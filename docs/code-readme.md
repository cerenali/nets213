## Aggregation Module 1

###aggregate1/majority_label.py

    USAGE: <labelled tweets>.csv | python2 majority_label.py > aggregate1_out.csv

This module takes the first HIT output, consisting of 7 label judgements for each tweet,
and takes majority vote to come up with the first- and second-place labels for each tweet.
Also aggregated for each tweet are the 7 'creative', or freeform entry, labels used to 
describe the tweet's social sphere.

## Aggregation Module 2

###aggregate2/match_creative.py

	python match_creative.py arg1.csv

Takes the output file from aggregate1 module as input. Compiles the creative and given label responses from the tweets and matches creative labels to one of our given labels based on majority. The format of the output: creative_label, corresponding_set_label. 

## Python Streaming Code

###twitter_stream/twitter_stream.py

	python twitter_stream.py -> outputfile.txt

Uses twitter streaming API with Tweepy to stream tweets in json format from twitter. This stream will only take tweets in English that are posted in the US. Writes to a specified output file as json. 

## JSON Parsing code

###twitter_stream/json_tweet_parser.py

	python json_tweet_parser.py inputfile.txt

Takes in the text file created from twitter_stream.py and extracts the text of each tweet and its corresponding url from the json dump. Tweets from verified sources are filtered out. This is returned as the csv file specified in line 8: "output = csv.writer(open('parsed_tweets.csv', 'w'))". The format of the output is text, url. 

## Classifier Training, Testing
This documents all the files in `src/classifier`

### classifier/prep_data.py

This module, found at `src/classifier`, handles training and testing a classifier that assigns labels
corresponding to social spheres for arbitrary lengths of text.

    cat <quality_control_output>.csv | python2 prep_data.py
    
Writes to `./training/` the following files:
* `family.train`
* `friends.train`
* `coworkers.train`
* `general.train`
* `specific.train`
Each file is of format:

        <0/1: is this the tweet's majority label>\t<tweet text>

Each file is used as training data for a binary classifier for the corresponding label.

### classifier/single_classifier.py

Constructs a binary unigram classifier for a label using training data in `data/training/'

    python2 single_classifier.py <training_data>
    

    import single_classifier
    single_classifier.get_classifier(<training file>)


### classifier/multi_classifier.py
This is the only part of the project not yet done. We've yet to combine the classifiers into a multi-label classifier.
One this is done, however, it will create 5 `single_classifier`s and combine them in a `OneVsRestClassifier`. 
The training files for the `single_classifiers` will be hard-coded into the file, so the only input is the test set.

    cat <test_tweets.tsv> | python2 multi_classifier.py > <test_results.txt>
    
The `test_tweets.tsv` file will be of format:

        <majority_label>\t<tweet text>

## HIT Code (for both crowdsourcing labels and quality control)

###crowdsource_labels/main-hit.html

The Quality Control HIT code is an HTML file that was generated by the Amazon Mechanical Turk graphical interface for designing a HIT. The main (crowdsourcing labels) HIT consists mostly of text, with two drop-down fields and a text input. All three must be filled out for the worker to be able to submit; the information is subsequently collected by Amazon MTurk into a CSV file that can be downloaded when the HITs have been completed. The quality control HIT is very similar, but instead of three questions, it only has one drop-down field, with the possible answers coming from the top two worker-picked answers of the previous (main) HIT. 



